# Personalizing Brain-computer interfaces with flexible machinen learning
## Kiret Dhindsa

The difficulty is that while the interface is trying to classify the signals the brain is changing the signals to try to make it easier. The brain signals are inconsistent but similar and change over time.

The choice of mental commands affects individual performance, the patients brain might not be that good at producing some forms of brain activity, if a person was paralysed for a decade the brain cells that used to signal hand movement might have been repurposed or atrophied

Using Feature learning to make BCIs more flexible

Most BCIs use Principal component analysis

The brain can be thought of as a giant oscillation machine in which neurons fire in sync, some small ones fire quickly and with low energy, the large ones are slower and have more energy.

using CSP there was not need to preprogramm what mental tasks produced what outcome and participants were able to choose almost and there was successful control with almost everyone. There are not deep learning pipelines for brain computer interfaces due to not working better than CSPs models and there is a problem with few data problem as you want a person to be able to start controlling something in a few minutes. Until that is solved BCIs will continue to use linear methods.

To comunicate to coma patients you can use the very unique brain response that is induced when you talk to them or about them in hearing range, use a deep learning network to classify that to figure out if you can actually speak to then and get responses through the BCI then you go about asking yes no questions.
